{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Load images**"
      ],
      "metadata": {
        "id": "lFejnQR0a-6k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYvnd7hn4FeW"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/DATA') #directories of drive items\n",
        "\n",
        "TRAIN_DIR = \"./DATASET\"#create path\n",
        "ORG_DIR = \"/content/train\"#create path\n",
        "CLASS = ['cat', 'dog']\n",
        "\n",
        "from zipfile import ZipFile\n",
        "with ZipFile('/content/DATA/MyDrive/Colab Notebooks/train.zip', 'r') as zipobj:\n",
        "    zipobj.extractall('/content/train') #extract train images\n",
        "\n",
        "with ZipFile('/content/DATA/MyDrive/Colab Notebooks/test.zip', 'r') as zipobj:\n",
        "    zipobj.extractall('/content/test') #extract test images"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Copy images based on name**"
      ],
      "metadata": {
        "id": "DfVX7X7cbF4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "\n",
        "for C in CLASS:\n",
        "    DEST = os.path.join(TRAIN_DIR, C) # just create path for classes\n",
        "\n",
        "    # if directory is not present then create one\n",
        "    if not os.path.exists( DEST ):\n",
        "        os.makedirs(DEST)\n",
        "\n",
        "    for img_path in glob.glob (os.path.join(ORG_DIR, C)+\"*\" ):\n",
        "        SRC = img_path\n",
        "        shutil.copy(SRC,DEST)"
      ],
      "metadata": {
        "id": "YW_4FuS3u5_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/content/train\")"
      ],
      "metadata": {
        "id": "PB3Ts8d2RQB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "#!pip install --upgrade keras\n",
        "!pip install keras==2.13.1rc0\n",
        "\n",
        "#!pip install --upgrade tensorflow\n",
        "!pip install tensorflow==2.12.0rc1\n"
      ],
      "metadata": {
        "id": "iy494Q08pH-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from keras.layers import Dense, Flatten"
      ],
      "metadata": {
        "id": "VwQKLe6VvNxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model # for functional API\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input # for pretrained model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras import losses"
      ],
      "metadata": {
        "id": "6SC0kCHerr7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Download InceptionV3 model\n",
        "base_model = InceptionV3(input_shape=(256,256,3), include_top= False)"
      ],
      "metadata": {
        "id": "7-PrzFvOxO_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False # we do not train"
      ],
      "metadata": {
        "id": "0onbWNwExRLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Model**"
      ],
      "metadata": {
        "id": "W8JtF9d8bSS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = Flatten()(base_model.output)\n",
        "X = Dense(units=2, activation='sigmoid')(X)  # Update units to 2\n",
        "model = Model(base_model.input, X)\n",
        "model.compile(optimizer='adam', loss=losses.binary_crossentropy, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Cqv0FB1RDJCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(featurewise_center= True,\n",
        "                                    rotation_range= 0.4,\n",
        "                                    width_shift_range= 0.3,\n",
        "                                    horizontal_flip= True,\n",
        "                                    preprocessing_function= preprocess_input,\n",
        "                                    zoom_range= 0.4,\n",
        "                                    shear_range= 0.4)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(directory=\"/content/DATASET\",\n",
        "                                                target_size=(256,256),\n",
        "                                                batch_size= 36)"
      ],
      "metadata": {
        "id": "XrtCOaqMa_u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_img , label = train_data.next()\n",
        "t_img.shape"
      ],
      "metadata": {
        "id": "mh9HwbBAczsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotImages(img_arr, label):\n",
        "    for idx, img in enumerate(img_arr):\n",
        "        if idx <= 5:\n",
        "            plt.figure(figsize=(5, 5))\n",
        "            plt.imshow(img, vmin=0, vmax=1)\n",
        "            plt.title(img.shape)\n",
        "            plt.axis = False\n",
        "            plt.show()\n",
        "plotImages(t_img , label)"
      ],
      "metadata": {
        "id": "W-Bq0Jkvdj3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Fitting**"
      ],
      "metadata": {
        "id": "XBSKDmCZbssE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "mc = ModelCheckpoint(filepath=\"./best_model.h5\",\n",
        "                    monitor=\"accuracy\",\n",
        "                    verbose= 1,\n",
        "                    save_best_only= True )\n",
        "\n",
        "es = EarlyStopping(monitor= \"accuracy\",\n",
        "                    min_delta = 0.02,\n",
        "                    patience= 5,\n",
        "                    verbose= 1)\n",
        "\n",
        "cb = [mc, es]"
      ],
      "metadata": {
        "id": "J0nW8fQRfGQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "his = model.fit_generator(train_data,\n",
        "                          steps_per_epoch= 10,\n",
        "                          epochs=10,\n",
        "                          callbacks= cb)"
      ],
      "metadata": {
        "id": "K77YbX9igLpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(\"/content/best_model.h5\")"
      ],
      "metadata": {
        "id": "LWIPR-M5kB33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot Loss & Accuracy**"
      ],
      "metadata": {
        "id": "-4ysIGD1cNjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h = his.history\n",
        "h.keys()"
      ],
      "metadata": {
        "id": "OzAaRhmZlJ90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\") # for ignoring warnings\n",
        "\n",
        "plt.plot(h['loss'] , 'go--' , c = \"green\" , )\n",
        "plt.plot(h['accuracy'] , 'go--' , c = \"blue\" , )\n",
        "\n",
        "plt.title(\"Loss vs Acc\")\n",
        "plt.show"
      ],
      "metadata": {
        "id": "CWFfrMaGmByz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Validate Model**"
      ],
      "metadata": {
        "id": "vqIFG0f7cVHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# path for the image to see if it predicts the correct class\n",
        "path = \"/content/test/dog.9783.jpg\"\n",
        "img = load_img(path, target_size=(256, 256))\n",
        "\n",
        "i = img_to_array(img)\n",
        "i = preprocess_input(i)\n",
        "input_arr = np.array([i])\n",
        "input_arr.shape\n",
        "\n",
        "pred = np.argmax(model.predict(input_arr))\n",
        "\n",
        "if pred == 0:\n",
        "    print(\"The image is of a cat\")\n",
        "else:\n",
        "    print(\"The image is of a dog\")\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(input_arr[0])\n",
        "plt.title(\"Input image\")\n",
        "#plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2aWrTDw_ZKSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_img_arrray(img_path):\n",
        "\n",
        "    img = load_img(path, target_size=(256,256))\n",
        "    img = img_to_array(img)\n",
        "    img = preprocess_input(img)\n",
        "    #expand the dimentions\n",
        "    img = np.array([img])\n",
        "    return img"
      ],
      "metadata": {
        "id": "9GOBqXBQr5Y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def make_gradcam_heatmap(img_path):\n",
        "    # Define the model architecture\n",
        "    model = tf.keras.applications.VGG19(weights='imagenet')\n",
        "\n",
        "    # Load the image\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "\n",
        "\n",
        "    # Get the output of the last convolutional layer\n",
        "    last_conv_layer = model.get_layer('block5_conv3')\n",
        "\n",
        "    # Create a new model that outputs both the predictions and the last conv layer output\n",
        "    heatmap_model = tf.keras.models.Model(model.input, (model.output, last_conv_layer.output))\n",
        "\n",
        "    # Compute the gradients of the predicted class with respect to the output feature map of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        preds, last_conv_layer_output = heatmap_model(x)\n",
        "        class_output = preds[:, np.argmax(preds[0])]\n",
        "        grads = tape.gradient(class_output, last_conv_layer_output)\n",
        "\n",
        "    # Global average pooling of the gradients\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # Multiply each channel in the feature map array by the corresponding gradient importance\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = tf.maximum(heatmap, 0)\n",
        "    heatmap /= tf.reduce_max(heatmap)\n",
        "\n",
        "    # Visualize the heatmap\n",
        "    plt.matshow(heatmap)\n",
        "    plt.show()\n",
        "\n",
        "    return heatmap.numpy()\n",
        "\n",
        "\n",
        "# Mask HeatMap on Image\n",
        "import matplotlib.cm as cm\n",
        "import tensorflow.keras as keras\n",
        "from IPython.display import Image, display\n",
        "\n",
        "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
        "    img = img_to_array(load_img(img_path))\n",
        "\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    jet_heatmap = cm.jet(np.arange(256))[:, :3]\n",
        "    jet_colors = jet_heatmap[heatmap]\n",
        "\n",
        "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_colors)\n",
        "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "    superimposed_img = jet_heatmap * alpha + img\n",
        "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "    superimposed_img.save(cam_path)\n",
        "    display(Image(cam_path))\n",
        "\n",
        "\n",
        "# image_prediction_and_visualization\n",
        "def image_prediction_and_visualization(path, last_conv_layer_name=\"conv2d_23\", model=model):\n",
        "    \"\"\"\n",
        "    Input: Image path, name of the last convolution layer, model name\n",
        "    Output: Predictions and the area that is affected\n",
        "    \"\"\"\n",
        "    img_array = get_img_arrray(path)\n",
        "    heatmap = make_gradcam_heatmap(path)\n",
        "    pred = np.argmax(model.predict(preprocess_input(img_array)))\n",
        "\n",
        "    if pred == 0:\n",
        "        print(\"The image is of a Cat\")\n",
        "    else:\n",
        "        print(\"The image is of a Dog\")\n",
        "\n",
        "    print(\"Image with heatmap representing region of interest\")\n",
        "\n",
        "    # Function call\n",
        "    save_and_display_gradcam(path, heatmap)\n",
        "\n",
        "    a = plt.imread(path)\n",
        "    #plt.imshow(a, camp =\"gray\")\n",
        "    plt.imshow(a, cmap=\"gray\")\n",
        "    plt.title(\"Original image\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# predictions\n",
        "\n",
        "path = \"/content/360_F_97589769_t45CqXyzjz0KXwoBZT9PRaWGHRk5hQqQ.jpg\"\n",
        "image_prediction_and_visualization(path)"
      ],
      "metadata": {
        "id": "UPJ3kmtvQNxg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}